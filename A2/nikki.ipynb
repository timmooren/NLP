{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\nikki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\nikki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\nikki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "nltk.download('brown')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### whole brown corpus ###\n",
    "corpus = [word for word in brown.words() if any(c.isalpha() for c in word)]\n",
    "\n",
    "# sorted list for whole corpus\n",
    "fdist = nltk.FreqDist([w.lower() for w in corpus])\n",
    "sorted_whole = sorted(fdist, key=fdist.get, reverse=True)\n",
    "# for word in sorted_whole[:10]:\n",
    "#     print(word, fdist[word])\n",
    "\n",
    "### sorted lists for two brown categories ###\n",
    "lore = brown.words(categories='lore')\n",
    "lore = [word for word in lore if any(c.isalpha() for c in word)]\n",
    "adventure = brown.words(categories='adventure')\n",
    "adventure = [word for word in adventure if any(c.isalpha() for c in word)]\n",
    "\n",
    "loredist = nltk.FreqDist([w.lower() for w in lore])\n",
    "advdist = nltk.FreqDist([w.lower() for w in adventure])\n",
    "\n",
    "sorted_lore = sorted(loredist, key=loredist.get, reverse=True)\n",
    "sorted_adv = sorted(advdist, key=advdist.get, reverse=True)\n",
    "\n",
    "# for word in sorted_lore[:10]:\n",
    "#     print(word, loredist[word])\n",
    "\n",
    "# for word in sorted_adv[:10]:\n",
    "#     print(word, advdist[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NN', 156580), ('IN', 136387), ('DT', 114735), ('JJ', 80467), ('NNP', 76598), ('NNS', 54215), ('VBD', 47175), ('RB', 45062), ('PRP', 44082), ('CC', 37957), ('VB', 34480), ('VBN', 27168), ('TO', 26158), ('VBZ', 21594), ('VBG', 17967), ('PRP$', 17306), ('VBP', 16516), ('MD', 12459), ('CD', 6879), ('WDT', 5633), ('WRB', 4385), ('WP', 4259), ('RP', 4173), ('JJR', 3055), ('EX', 2335), ('JJS', 1956), ('RBR', 1755), ('NNPS', 1709), ('PDT', 952), ('RBS', 661), ('WP$', 250), ('FW', 172), ('UH', 23), ('POS', 10), ('$', 3), (\"''\", 3)]\n"
     ]
    }
   ],
   "source": [
    "# number of tokens\n",
    "whole = brown.words()\n",
    "print(f\"nr of tokens, with punctuation: {len(whole)}\")  \n",
    "print(f\"nr of tokens, without punctuation: {len(corpus)}\")\n",
    "\n",
    "# number of types and words\n",
    "print(f\"nr of types: {len(set(whole))}\") # print(f\" {}\")\n",
    "print(f\"nr of words: {len(corpus)}\")\n",
    "\n",
    "# average number of words per sentence; average word length\n",
    "print(f\"average nr of words per sentence: {len(corpus)/len(brown.sents())}\")\n",
    "count = 0\n",
    "for word in corpus:\n",
    "    count += len(word)\n",
    "print(f\"average word length: {count / len(corpus)}\")\n",
    "\n",
    "# POS tags\n",
    "tagged = nltk.pos_tag(corpus)\n",
    "# print(tagged[:10])\n",
    "# print(brown.tagged_words(tagset='universal')[:10])\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in tagged)\n",
    "print(f\"10 most frequent POS-tags: {tag_fd.most_common()[:10]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE SLOW, DOES NOT WORK'\n",
    "\n",
    "# plt.plot(list(fdist.keys()), list(fdist.values()), label='corpus', color='black')  # plot the frequency curve for the corpus\n",
    "# plt.xlabel('Rank')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
